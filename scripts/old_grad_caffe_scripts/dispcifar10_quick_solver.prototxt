# reduce the learning rate after 8 epochs (4000 iters) by a factor of 10

# The training protocol buffer definition
train_net: "dispcifar10_quick_train.prototxt"
# The testing protocol buffer definition
test_net: "dispcifar10_quick_test.prototxt"
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 10
# Carry out testing every 500 training iterations.
test_interval: 10

# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.0001 # dont change, adjusted from sh
momentum: 0.9 # dont change, adjusted from sh
weight_decay: 0.00004 # dont change, adjusted from sh

# The learning rate policy
lr_policy: "fixed"
gamma: 0.05
stepsize: 20000 # -> disabled

# Display every 10 iterations
display: 100
# The maximum number of iterations (also do not change)
max_iter: 1000
# snapshot intermediate results (also do not change)
snapshot: 500
snapshot_prefix: "snapshots/dispcifar10_quick"
# solver mode: 0 for CPU and 1 for GPU
solver_mode: 0

test_compute_loss: true
